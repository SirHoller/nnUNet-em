{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install batchgeneratorsv2\n",
    "\n",
    "import torch\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\mrtwe\\\\TFM\\\\nnUNet-em'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables set: nnUNet_raw, nnUNet_preprocessed, nnUNet_results\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_raw_data\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "from scripts.A_config import NNUNetConfig, DatasetType\n",
    "NNUNetConfig().export_paths_to_env()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnunetv2.run.run_training import run_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El entorno utiliza:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Comprobación de entorno con gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"El entorno utiliza: \", device)\n",
    "# # Comprobación de entorno con gpu M1\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# print(\"El entorno utiliza: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "torch.set_num_interop_threads(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "2024-12-09 18:40:06.591291: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.33\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-12-09 18:40:06.593162: Using early stopping with patience: 100\n",
      "2024-12-09 18:40:06.602002: self.oversample_foreground_percent 0.5\n",
      "2024-12-09 18:40:06.605128: self.oversample_foreground_percent 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "c:\\Users\\mrtwe\\miniforge3\\envs\\TFM\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-09 18:40:07.968802: Using splits from existing split file: C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\\Dataset100_NewLesions\\splits_final.json\n",
      "2024-12-09 18:40:07.968802: The split file contains 5 splits.\n",
      "2024-12-09 18:40:07.986731: Desired fold for training: 7\n",
      "2024-12-09 18:40:07.993243: INFO: You requested fold 7 for training but splits contain only 5 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2024-12-09 18:40:07.993243: This random 80:20 split has 64 training and 17 validation cases.\n",
      "2024-12-09 18:40:08.000248: predicting FIS_012_01\n",
      "2024-12-09 18:40:08.000248: FIS_012_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:12.154596: predicting FIS_028_01\n",
      "2024-12-09 18:40:12.168538: FIS_028_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:15.225878: predicting FIS_033_01\n",
      "2024-12-09 18:40:15.241503: FIS_033_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:18.329940: predicting FIS_037_01\n",
      "2024-12-09 18:40:18.345564: FIS_037_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:21.422635: predicting FIS_046_01\n",
      "2024-12-09 18:40:21.432124: FIS_046_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:24.505693: predicting FIS_104_01\n",
      "2024-12-09 18:40:24.515384: FIS_104_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:27.557431: predicting FIS_107_01\n",
      "2024-12-09 18:40:27.571390: FIS_107_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:30.627872: predicting FIS_117_01\n",
      "2024-12-09 18:40:30.633666: FIS_117_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:33.673661: predicting REHEM_08_01\n",
      "2024-12-09 18:40:33.685658: REHEM_08_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:36.725288: predicting REHEM_121_01\n",
      "2024-12-09 18:40:36.731382: REHEM_121_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:39.814738: predicting REHEM_22_01\n",
      "2024-12-09 18:40:39.828651: REHEM_22_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:42.932961: predicting REHEM_37_01\n",
      "2024-12-09 18:40:42.947725: REHEM_37_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:46.037139: predicting REHEM_41_01\n",
      "2024-12-09 18:40:46.052772: REHEM_41_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:49.128530: predicting REHEM_60_01\n",
      "2024-12-09 18:40:49.142442: REHEM_60_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:52.174276: predicting REHEM_67_01\n",
      "2024-12-09 18:40:52.186293: REHEM_67_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:55.232634: predicting REHEM_95_01\n",
      "2024-12-09 18:40:55.245932: REHEM_95_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:40:58.273544: predicting REHEM_97_01\n",
      "2024-12-09 18:40:58.293583: REHEM_97_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:41:04.486230: Validation complete\n",
      "2024-12-09 18:41:04.492203: Mean Validation Dice:  0.5374493370563668\n"
     ]
    }
   ],
   "source": [
    "# NNUNetConfig().export_paths_to_env()\n",
    "\n",
    "run_training(\n",
    "        dataset_name_or_id=\"100\",\n",
    "        fold=\"7\",\n",
    "        device=device,\n",
    "        configuration=NNUNetConfig().CONFIGURATION,\n",
    "        trainer_class_name=\"nnUNetTrainerCustomOversamplingEarlyStopping\",\n",
    "        export_validation_probabilities=False,\n",
    "        only_run_validation=True,\n",
    "        val_with_best=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
