{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install batchgeneratorsv2\n",
    "\n",
    "import torch\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\mrtwe\\\\TFM\\\\nnUNet-em'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables set: nnUNet_raw, nnUNet_preprocessed, nnUNet_results\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_raw_data\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "from scripts.A_config import NNUNetConfig, DatasetType\n",
    "NNUNetConfig().export_paths_to_env()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnunetv2.run.run_training import run_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El entorno utiliza:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Comprobación de entorno con gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"El entorno utiliza: \", device)\n",
    "# # Comprobación de entorno con gpu M1\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# print(\"El entorno utiliza: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "torch.set_num_interop_threads(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "2024-12-09 18:37:26.096009: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.33\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-12-09 18:37:26.096009: Using early stopping with patience: 100\n",
      "2024-12-09 18:37:26.111638: self.oversample_foreground_percent 0.5\n",
      "2024-12-09 18:37:26.111638: self.oversample_foreground_percent 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "c:\\Users\\mrtwe\\miniforge3\\envs\\TFM\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-09 18:37:27.398442: Using splits from existing split file: C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\\Dataset100_NewLesions\\splits_final.json\n",
      "2024-12-09 18:37:27.405373: The split file contains 5 splits.\n",
      "2024-12-09 18:37:27.412300: Desired fold for training: 6\n",
      "2024-12-09 18:37:27.412300: INFO: You requested fold 6 for training but splits contain only 5 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2024-12-09 18:37:27.419238: This random 80:20 split has 64 training and 17 validation cases.\n",
      "2024-12-09 18:37:27.426156: predicting FIS_019_01\n",
      "2024-12-09 18:37:27.433186: FIS_019_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:37:31.671885: predicting FIS_041_01\n",
      "2024-12-09 18:37:31.687899: FIS_041_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:37:34.817331: predicting FIS_097_01\n",
      "2024-12-09 18:37:34.831018: FIS_097_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:37:37.961099: predicting FIS_099_01\n",
      "2024-12-09 18:37:37.976748: FIS_099_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:37:41.098687: predicting FIS_110_01\n",
      "2024-12-09 18:37:41.114322: FIS_110_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:37:44.273855: predicting FIS_116_01\n",
      "2024-12-09 18:37:44.298247: FIS_116_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:37:47.394049: predicting FIS_122_01\n",
      "2024-12-09 18:37:47.406114: FIS_122_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:37:50.485201: predicting REHEM_08_01\n",
      "2024-12-09 18:37:50.498291: REHEM_08_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:37:53.531344: predicting REHEM_101_01\n",
      "2024-12-09 18:37:53.545182: REHEM_101_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:37:56.518770: predicting REHEM_108_01\n",
      "2024-12-09 18:37:56.536880: REHEM_108_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:37:59.504636: predicting REHEM_111_01\n",
      "2024-12-09 18:37:59.517140: REHEM_111_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:38:02.507024: predicting REHEM_13_01\n",
      "2024-12-09 18:38:02.515531: REHEM_13_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:38:05.506568: predicting REHEM_23_01\n",
      "2024-12-09 18:38:05.510076: REHEM_23_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:38:08.522728: predicting REHEM_55_01\n",
      "2024-12-09 18:38:08.538361: REHEM_55_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:38:11.605447: predicting REHEM_59_01\n",
      "2024-12-09 18:38:11.616111: REHEM_59_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:38:14.698805: predicting REHEM_68_01\n",
      "2024-12-09 18:38:14.705702: REHEM_68_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-09 18:38:17.865528: predicting REHEM_80_01\n",
      "2024-12-09 18:38:17.872481: REHEM_80_01, shape torch.Size([2, 182, 218, 182]), rank 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception thrown in SimpleITK ImageFileReader_Execute: D:\\a\\1\\sitk\\Code\\IO\\src\\sitkImageReaderBase.cxx:97:\nsitk::ERROR: The file \"C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\\Dataset100_NewLesions\\gt_segmentations\\FIS_127_01.nii.gz\" does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\mrtwe\\miniforge3\\envs\\TFM\\lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"c:\\Users\\mrtwe\\miniforge3\\envs\\TFM\\lib\\multiprocessing\\pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\evaluation\\evaluate_predictions.py\", line 93, in compute_metrics\n    seg_ref, seg_ref_dict = image_reader_writer.read_seg(reference_file)\n  File \"C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\imageio\\simpleitk_reader_writer.py\", line 115, in read_seg\n    return self.read_images((seg_fname, ))\n  File \"C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\imageio\\simpleitk_reader_writer.py\", line 38, in read_images\n    itk_image = sitk.ReadImage(f)\n  File \"c:\\Users\\mrtwe\\miniforge3\\envs\\TFM\\lib\\site-packages\\SimpleITK\\extra.py\", line 355, in ReadImage\n    return reader.Execute()\n  File \"c:\\Users\\mrtwe\\miniforge3\\envs\\TFM\\lib\\site-packages\\SimpleITK\\SimpleITK.py\", line 8438, in Execute\n    return _SimpleITK.ImageFileReader_Execute(self)\nRuntimeError: Exception thrown in SimpleITK ImageFileReader_Execute: D:\\a\\1\\sitk\\Code\\IO\\src\\sitkImageReaderBase.cxx:97:\nsitk::ERROR: The file \"C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\\Dataset100_NewLesions\\gt_segmentations\\FIS_127_01.nii.gz\" does not exist.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# NNUNetConfig().export_paths_to_env()\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_name_or_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m100\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNNUNetConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCONFIGURATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainer_class_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnnUNetTrainerCustomOversamplingEarlyStopping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_validation_probabilities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_run_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_with_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\run\\run_training.py:215\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(dataset_name_or_id, configuration, fold, trainer_class_name, plans_identifier, pretrained_weights, num_gpus, use_compressed_data, export_validation_probabilities, continue_training, only_run_validation, disable_checkpointing, val_with_best, device)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_with_best:\n\u001b[0;32m    214\u001b[0m     nnunet_trainer\u001b[38;5;241m.\u001b[39mload_checkpoint(join(nnunet_trainer\u001b[38;5;241m.\u001b[39moutput_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_best.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m--> 215\u001b[0m \u001b[43mnnunet_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_actual_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_validation_probabilities\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:1344\u001b[0m, in \u001b[0;36mnnUNetTrainer.perform_actual_validation\u001b[1;34m(self, save_probabilities)\u001b[0m\n\u001b[0;32m   1341\u001b[0m     dist\u001b[38;5;241m.\u001b[39mbarrier()\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1344\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_metrics_on_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessed_dataset_folder_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgt_segmentations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1345\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mvalidation_output_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_output_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msummary.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplans_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_reader_writer_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile_ending\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeground_regions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_regions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\n\u001b[0;32m   1350\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeground_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1352\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_num_processes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_world_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\n\u001b[0;32m   1353\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ddp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefault_num_processes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_to_log_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, also_print_to_console\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_to_log_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Validation Dice: \u001b[39m\u001b[38;5;124m\"\u001b[39m, (metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeground_mean\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDice\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m   1356\u001b[0m                            also_print_to_console\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\evaluation\\evaluate_predictions.py:144\u001b[0m, in \u001b[0;36mcompute_metrics_on_folder\u001b[1;34m(folder_ref, folder_pred, output_file, image_reader_writer, file_ending, regions_or_labels, ignore_label, num_processes, chill)\u001b[0m\n\u001b[0;32m    140\u001b[0m files_pred \u001b[38;5;241m=\u001b[39m [join(folder_pred, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m files_pred]\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mget_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mPool(num_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# for i in list(zip(files_ref, files_pred, [image_reader_writer] * len(files_pred), [regions_or_labels] * len(files_pred), [ignore_label] * len(files_pred))):\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;66;03m#     compute_metrics(*i)\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiles_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_reader_writer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiles_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mregions_or_labels\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiles_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m                 \u001b[49m\u001b[43m[\u001b[49m\u001b[43mignore_label\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiles_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# mean metric per class\u001b[39;00m\n\u001b[0;32m    151\u001b[0m metric_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(results[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m][regions_or_labels[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\Users\\mrtwe\\miniforge3\\envs\\TFM\\lib\\multiprocessing\\pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mrtwe\\miniforge3\\envs\\TFM\\lib\\multiprocessing\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exception thrown in SimpleITK ImageFileReader_Execute: D:\\a\\1\\sitk\\Code\\IO\\src\\sitkImageReaderBase.cxx:97:\nsitk::ERROR: The file \"C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\\Dataset100_NewLesions\\gt_segmentations\\FIS_127_01.nii.gz\" does not exist."
     ]
    }
   ],
   "source": [
    "# NNUNetConfig().export_paths_to_env()\n",
    "\n",
    "run_training(\n",
    "        dataset_name_or_id=\"100\",\n",
    "        fold=\"7\",\n",
    "        device=device,\n",
    "        configuration=NNUNetConfig().CONFIGURATION,\n",
    "        trainer_class_name=\"nnUNetTrainerCustomOversamplingEarlyStopping\",\n",
    "        export_validation_probabilities=False,\n",
    "        only_run_validation=True,\n",
    "        val_with_best=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
