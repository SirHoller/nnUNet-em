{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install batchgeneratorsv2\n",
    "\n",
    "import torch\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\mrtwe\\\\TFM\\\\nnUNet-em'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables set: nnUNet_raw, nnUNet_preprocessed, nnUNet_results\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_raw_data\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "from scripts.A_config import NNUNetConfig, DatasetType\n",
    "NNUNetConfig().export_paths_to_env()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnunetv2.run.run_training import run_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El entorno utiliza:  cuda\n"
     ]
    }
   ],
   "source": [
    "# ComprobaciÃ³n de entorno con gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"El entorno utiliza: \", device)\n",
    "# # ComprobaciÃ³n de entorno con gpu M1\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# print(\"El entorno utiliza: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "torch.set_num_interop_threads(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "2024-12-09 18:39:40.909000: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.33\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-12-09 18:39:40.914999: Using early stopping with patience: 100\n",
      "2024-12-09 18:39:40.918647: self.oversample_foreground_percent 0.5\n",
      "2024-12-09 18:39:40.921362: self.oversample_foreground_percent 1.0\n",
      "2024-12-09 18:39:40.921362: nnUNetTrainerCustomOversamplingEarlyStopping, get_dataloaders\n",
      "2024-12-09 18:39:40.921362: do_dummy_2d_data_aug: False\n",
      "2024-12-09 18:39:40.921362: Using splits from existing split file: C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\\Dataset100_NewLesions\\splits_final.json\n",
      "2024-12-09 18:39:40.937029: The split file contains 5 splits.\n",
      "2024-12-09 18:39:40.940612: Desired fold for training: 7\n",
      "2024-12-09 18:39:40.940612: INFO: You requested fold 7 for training but splits contain only 5 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2024-12-09 18:39:40.946356: This random 80:20 split has 64 training and 17 validation cases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: {0: 0.9984419362599418, 1: 0.0015334243429471024, 2: 2.463939711110545e-05}\n",
      "Class distribution: {0: 0.9976490732007477, 1: 0.0023184318513247543, 2: 3.249494792759946e-05}\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# NNUNetConfig().export_paths_to_env()\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_name_or_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m100\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNNUNetConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCONFIGURATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainer_class_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnnUNetTrainerCustomOversamplingEarlyStopping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_validation_probabilities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontinue_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\run\\run_training.py:211\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(dataset_name_or_id, configuration, fold, trainer_class_name, plans_identifier, pretrained_weights, num_gpus, use_compressed_data, export_validation_probabilities, continue_training, only_run_validation, disable_checkpointing, val_with_best, device)\u001b[0m\n\u001b[0;32m    208\u001b[0m     cudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_run_validation:\n\u001b[1;32m--> 211\u001b[0m     \u001b[43mnnunet_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_with_best:\n\u001b[0;32m    214\u001b[0m     nnunet_trainer\u001b[38;5;241m.\u001b[39mload_checkpoint(join(nnunet_trainer\u001b[38;5;241m.\u001b[39moutput_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_best.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\training\\nnUNetTrainer\\variants\\early_stop\\nnUnetTrainerEarlyStop.py:79\u001b[0m, in \u001b[0;36mnnUNetTrainerEarlyStopping.run_training\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_training\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs):\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_epoch_start()\n",
      "File \u001b[1;32mc:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:903\u001b[0m, in \u001b[0;36mnnUNetTrainer.on_train_start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_start\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;66;03m# dataloaders must be instantiated here (instead of __init__) because they need access to the training data\u001b[39;00m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;66;03m# which may not be present  when doing inference\u001b[39;00m\n\u001b[1;32m--> 903\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwas_initialized:\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\training\\nnUNetTrainer\\variants\\early_stop\\nnUnetTrainerEarlyStop.py:225\u001b[0m, in \u001b[0;36mnnUNetTrainerCustomOversamplingEarlyStopping.get_dataloaders\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# # let's get this party started\u001b[39;00m\n\u001b[0;32m    224\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(mt_gen_train)\n\u001b[1;32m--> 225\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmt_gen_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mt_gen_train, mt_gen_val\n",
      "File \u001b[1;32mc:\\Users\\mrtwe\\miniforge3\\envs\\TFM\\lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py:196\u001b[0m, in \u001b[0;36mNonDetMultiThreadedAugmenter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialized:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start()\n\u001b[1;32m--> 196\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_next_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m item\n",
      "File \u001b[1;32mc:\\Users\\mrtwe\\miniforge3\\envs\\TFM\\lib\\site-packages\\batchgenerators\\dataloading\\nondet_multi_threaded_augmenter.py:188\u001b[0m, in \u001b[0;36mNonDetMultiThreadedAugmenter.__get_next_item\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_loop_queue\u001b[38;5;241m.\u001b[39mtask_done()\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 188\u001b[0m         \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m item\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# NNUNetConfig().export_paths_to_env()\n",
    "\n",
    "run_training(\n",
    "        dataset_name_or_id=\"100\",\n",
    "        fold=\"7\",\n",
    "        device=device,\n",
    "        configuration=NNUNetConfig().CONFIGURATION,\n",
    "        trainer_class_name=\"nnUNetTrainerCustomOversamplingEarlyStopping\",\n",
    "        export_validation_probabilities=True,\n",
    "        continue_training=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
