{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración del entorno de ejec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\mrtwe\\\\TFM\\\\nnUNet-em'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables set: nnUNet_raw, nnUNet_preprocessed, nnUNet_results\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_raw_data\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\n",
      "C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "from scripts.A_config import NNUNetConfig, DatasetType\n",
    "NNUNetConfig().export_paths_to_env()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnunetv2.run.run_training import run_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar entorno de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El entorno utiliza:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Comprobación de entorno con gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"El entorno utiliza: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "torch.set_num_interop_threads(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "2024-12-15 14:54:59.238301: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.33\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-12-15 14:54:59.243301: Using early stopping with patience: 100\n",
      "2024-12-15 14:54:59.245808: self.oversample_foreground_percent 0.5\n",
      "2024-12-15 14:54:59.249308: nnUNetTrainerCustomOversamplingEarlyStopping, get_dataloaders\n",
      "2024-12-15 14:54:59.252307: do_dummy_2d_data_aug: False\n",
      "2024-12-15 14:54:59.255812: Using splits from existing split file: C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\\Dataset100_NewLesions\\splits_final.json\n",
      "2024-12-15 14:54:59.258840: The split file contains 5 splits.\n",
      "2024-12-15 14:54:59.261844: Desired fold for training: 3\n",
      "2024-12-15 14:54:59.265844: This split has 65 training and 16 validation cases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrtwe\\miniforge3\\envs\\TFM\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom loss\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [182.0, 218.0, 182.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset100_NewLesions', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [182, 218, 182], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 166.00692749023438, 'mean': 93.82862854003906, 'median': 98.19132232666016, 'min': 1.0409830808639526, 'percentile_00_5': 52.173828125, 'percentile_99_5': 105.61139678955078, 'std': 10.065444946289062}, '1': {'max': 114.52489471435547, 'mean': 91.6470718383789, 'median': 96.5392074584961, 'min': 1.000115990638733, 'percentile_00_5': 18.539852142333984, 'percentile_99_5': 105.64462280273438, 'std': 12.845990180969238}}} \n",
      "\n",
      "2024-12-15 14:55:12.640817: unpacking dataset...\n",
      "2024-12-15 14:55:12.847556: unpacking done...\n",
      "2024-12-15 14:55:12.854558: Unable to plot network architecture:\n",
      "2024-12-15 14:55:12.860570: module 'torch.jit' has no attribute 'get_trace_graph'\n",
      "2024-12-15 14:55:12.880433: \n",
      "2024-12-15 14:55:12.884433: Epoch 0\n",
      "2024-12-15 14:55:12.888460: Current learning rate: 0.01\n",
      "2024-12-15 14:56:15.646778: train_loss 0.1321\n",
      "2024-12-15 14:56:15.646778: val_loss 0.0264\n",
      "2024-12-15 14:56:15.654788: Pseudo dice [0.5718, 0.359]\n",
      "2024-12-15 14:56:15.659806: Epoch time: 62.77 s\n",
      "2024-12-15 14:56:15.663806: Yayy! New best EMA pseudo Dice: 0.4654\n",
      "2024-12-15 14:56:16.601525: \n",
      "2024-12-15 14:56:16.601525: Epoch 1\n",
      "2024-12-15 14:56:16.607949: Current learning rate: 0.00999\n",
      "2024-12-15 14:57:14.674219: train_loss -0.0594\n",
      "2024-12-15 14:57:14.674219: val_loss -0.0429\n",
      "2024-12-15 14:57:14.681231: Pseudo dice [0.5299, 0.5798]\n",
      "2024-12-15 14:57:14.686739: Epoch time: 58.07 s\n",
      "2024-12-15 14:57:14.690244: Yayy! New best EMA pseudo Dice: 0.4743\n",
      "EarlyStopping: 1 / 100\n",
      "2024-12-15 14:57:15.543147: \n",
      "2024-12-15 14:57:15.543147: Epoch 2\n",
      "2024-12-15 14:57:15.549176: Current learning rate: 0.00998\n",
      "2024-12-15 14:58:13.854189: train_loss -0.113\n",
      "2024-12-15 14:58:13.854189: val_loss -0.0379\n",
      "2024-12-15 14:58:13.862200: Pseudo dice [0.6497, 0.4702]\n",
      "2024-12-15 14:58:13.867209: Epoch time: 58.31 s\n",
      "2024-12-15 14:58:13.872213: Yayy! New best EMA pseudo Dice: 0.4829\n",
      "EarlyStopping: 2 / 100\n",
      "2024-12-15 14:58:14.751744: \n",
      "2024-12-15 14:58:14.751744: Epoch 3\n",
      "2024-12-15 14:58:14.757048: Current learning rate: 0.00997\n",
      "2024-12-15 14:59:12.917553: train_loss -0.164\n",
      "2024-12-15 14:59:12.917553: val_loss -0.1054\n",
      "2024-12-15 14:59:12.925556: Pseudo dice [0.6969, 0.6288]\n",
      "2024-12-15 14:59:12.930569: Epoch time: 58.17 s\n",
      "2024-12-15 14:59:12.935568: Yayy! New best EMA pseudo Dice: 0.5009\n",
      "2024-12-15 14:59:13.978468: \n",
      "2024-12-15 14:59:13.978468: Epoch 4\n",
      "2024-12-15 14:59:13.985972: Current learning rate: 0.00996\n",
      "2024-12-15 15:00:11.917885: train_loss -0.1689\n",
      "2024-12-15 15:00:11.917885: val_loss -0.1592\n",
      "2024-12-15 15:00:11.926401: Pseudo dice [0.656, 0.6406]\n",
      "2024-12-15 15:00:11.931406: Epoch time: 57.94 s\n",
      "2024-12-15 15:00:11.935910: Yayy! New best EMA pseudo Dice: 0.5156\n",
      "2024-12-15 15:00:12.992214: \n",
      "2024-12-15 15:00:12.993213: Epoch 5\n",
      "2024-12-15 15:00:12.998237: Current learning rate: 0.00995\n",
      "2024-12-15 15:01:10.881442: train_loss -0.2113\n",
      "2024-12-15 15:01:10.882442: val_loss -0.2456\n",
      "2024-12-15 15:01:10.889468: Pseudo dice [0.7127, 0.6663]\n",
      "2024-12-15 15:01:10.894467: Epoch time: 57.89 s\n",
      "2024-12-15 15:01:10.898985: Yayy! New best EMA pseudo Dice: 0.533\n",
      "2024-12-15 15:01:11.928469: \n",
      "2024-12-15 15:01:11.929469: Epoch 6\n",
      "2024-12-15 15:01:11.936486: Current learning rate: 0.00995\n",
      "2024-12-15 15:02:09.808377: train_loss -0.2414\n",
      "2024-12-15 15:02:09.808377: val_loss -0.2495\n",
      "2024-12-15 15:02:09.817390: Pseudo dice [0.6734, 0.6111]\n",
      "2024-12-15 15:02:09.822395: Epoch time: 57.88 s\n",
      "2024-12-15 15:02:09.826442: Yayy! New best EMA pseudo Dice: 0.5439\n",
      "2024-12-15 15:02:10.976480: \n",
      "2024-12-15 15:02:10.976480: Epoch 7\n",
      "2024-12-15 15:02:10.982489: Current learning rate: 0.00994\n",
      "2024-12-15 15:03:08.742123: train_loss -0.2425\n",
      "2024-12-15 15:03:08.743122: val_loss -0.2591\n",
      "2024-12-15 15:03:08.751143: Pseudo dice [0.7063, 0.6922]\n",
      "2024-12-15 15:03:08.755647: Epoch time: 57.77 s\n",
      "2024-12-15 15:03:08.760164: Yayy! New best EMA pseudo Dice: 0.5595\n",
      "2024-12-15 15:03:09.824352: \n",
      "2024-12-15 15:03:09.824352: Epoch 8\n",
      "2024-12-15 15:03:09.830507: Current learning rate: 0.00993\n",
      "2024-12-15 15:04:07.668210: train_loss -0.2787\n",
      "2024-12-15 15:04:07.669210: val_loss -0.261\n",
      "2024-12-15 15:04:07.675735: Pseudo dice [0.6865, 0.6181]\n",
      "2024-12-15 15:04:07.680243: Epoch time: 57.84 s\n",
      "2024-12-15 15:04:07.684242: Yayy! New best EMA pseudo Dice: 0.5688\n",
      "EarlyStopping: 1 / 100\n",
      "2024-12-15 15:04:08.556288: \n",
      "2024-12-15 15:04:08.556793: Epoch 9\n",
      "2024-12-15 15:04:08.561800: Current learning rate: 0.00992\n",
      "2024-12-15 15:05:06.885851: train_loss -0.2699\n",
      "2024-12-15 15:05:06.885851: val_loss -0.3035\n",
      "2024-12-15 15:05:06.893358: Pseudo dice [0.7218, 0.7776]\n",
      "2024-12-15 15:05:06.897368: Epoch time: 58.33 s\n",
      "2024-12-15 15:05:06.902370: Yayy! New best EMA pseudo Dice: 0.5868\n",
      "2024-12-15 15:05:07.924150: \n",
      "2024-12-15 15:05:07.924150: Epoch 10\n",
      "2024-12-15 15:05:07.931170: Current learning rate: 0.00991\n",
      "2024-12-15 15:06:05.725898: train_loss -0.2796\n",
      "2024-12-15 15:06:05.726401: val_loss -0.2454\n",
      "2024-12-15 15:06:05.732910: Pseudo dice [0.706, 0.738]\n",
      "2024-12-15 15:06:05.737413: Epoch time: 57.8 s\n",
      "2024-12-15 15:06:05.741415: Yayy! New best EMA pseudo Dice: 0.6004\n",
      "2024-12-15 15:06:06.768210: \n",
      "2024-12-15 15:06:06.768210: Epoch 11\n",
      "2024-12-15 15:06:06.774211: Current learning rate: 0.0099\n",
      "2024-12-15 15:07:04.422240: train_loss -0.2914\n",
      "2024-12-15 15:07:04.423239: val_loss -0.3025\n",
      "2024-12-15 15:07:04.429251: Pseudo dice [0.6896, 0.7077]\n",
      "2024-12-15 15:07:04.434252: Epoch time: 57.66 s\n",
      "2024-12-15 15:07:04.438262: Yayy! New best EMA pseudo Dice: 0.6102\n",
      "EarlyStopping: 1 / 100\n",
      "2024-12-15 15:07:05.294805: \n",
      "2024-12-15 15:07:05.295819: Epoch 12\n",
      "2024-12-15 15:07:05.301438: Current learning rate: 0.00989\n",
      "2024-12-15 15:08:03.146261: train_loss -0.307\n",
      "2024-12-15 15:08:03.147148: val_loss -0.2829\n",
      "2024-12-15 15:08:03.154773: Pseudo dice [0.6433, 0.7586]\n",
      "2024-12-15 15:08:03.159790: Epoch time: 57.85 s\n",
      "2024-12-15 15:08:03.163790: Yayy! New best EMA pseudo Dice: 0.6193\n",
      "EarlyStopping: 2 / 100\n",
      "2024-12-15 15:08:04.043792: \n",
      "2024-12-15 15:08:04.044794: Epoch 13\n",
      "2024-12-15 15:08:04.049807: Current learning rate: 0.00988\n",
      "2024-12-15 15:09:01.882282: train_loss -0.2915\n",
      "2024-12-15 15:09:01.883285: val_loss -0.2665\n",
      "2024-12-15 15:09:01.891293: Pseudo dice [0.6907, 0.7634]\n",
      "2024-12-15 15:09:01.895797: Epoch time: 57.84 s\n",
      "2024-12-15 15:09:01.900307: Yayy! New best EMA pseudo Dice: 0.6301\n",
      "2024-12-15 15:09:03.050678: \n",
      "2024-12-15 15:09:03.050678: Epoch 14\n",
      "2024-12-15 15:09:03.056687: Current learning rate: 0.00987\n",
      "2024-12-15 15:10:00.783309: train_loss -0.3127\n",
      "2024-12-15 15:10:00.783309: val_loss -0.2861\n",
      "2024-12-15 15:10:00.790323: Pseudo dice [0.7005, 0.7473]\n",
      "2024-12-15 15:10:00.795831: Epoch time: 57.73 s\n",
      "2024-12-15 15:10:00.800844: Yayy! New best EMA pseudo Dice: 0.6394\n",
      "EarlyStopping: 1 / 100\n",
      "2024-12-15 15:10:01.673485: \n",
      "2024-12-15 15:10:01.674485: Epoch 15\n",
      "2024-12-15 15:10:01.679501: Current learning rate: 0.00986\n",
      "2024-12-15 15:10:59.333268: train_loss -0.3174\n",
      "2024-12-15 15:10:59.333268: val_loss -0.2347\n",
      "2024-12-15 15:10:59.340281: Pseudo dice [0.6967, 0.7226]\n",
      "2024-12-15 15:10:59.345795: Epoch time: 57.66 s\n",
      "2024-12-15 15:10:59.349806: Yayy! New best EMA pseudo Dice: 0.6465\n",
      "EarlyStopping: 2 / 100\n",
      "2024-12-15 15:11:00.242785: \n",
      "2024-12-15 15:11:00.242785: Epoch 16\n",
      "2024-12-15 15:11:00.249163: Current learning rate: 0.00986\n",
      "2024-12-15 15:11:58.001496: train_loss -0.2965\n",
      "2024-12-15 15:11:58.001496: val_loss -0.2814\n",
      "2024-12-15 15:11:58.009019: Pseudo dice [0.6811, 0.7173]\n",
      "2024-12-15 15:11:58.014018: Epoch time: 57.76 s\n",
      "2024-12-15 15:11:58.019031: Yayy! New best EMA pseudo Dice: 0.6517\n",
      "EarlyStopping: 3 / 100\n",
      "2024-12-15 15:11:58.899136: \n",
      "2024-12-15 15:11:58.900135: Epoch 17\n",
      "2024-12-15 15:11:58.904136: Current learning rate: 0.00985\n",
      "2024-12-15 15:12:56.705823: train_loss -0.2963\n",
      "2024-12-15 15:12:56.706827: val_loss -0.2808\n",
      "2024-12-15 15:12:56.713335: Pseudo dice [0.653, 0.7512]\n",
      "2024-12-15 15:12:56.718348: Epoch time: 57.81 s\n",
      "2024-12-15 15:12:56.723347: Yayy! New best EMA pseudo Dice: 0.6568\n",
      "EarlyStopping: 4 / 100\n",
      "2024-12-15 15:12:57.612106: \n",
      "2024-12-15 15:12:57.612106: Epoch 18\n",
      "2024-12-15 15:12:57.618124: Current learning rate: 0.00984\n",
      "2024-12-15 15:13:55.284153: train_loss -0.3219\n",
      "2024-12-15 15:13:55.284153: val_loss -0.3264\n",
      "2024-12-15 15:13:55.291166: Pseudo dice [0.671, 0.7135]\n",
      "2024-12-15 15:13:55.296672: Epoch time: 57.67 s\n",
      "2024-12-15 15:13:55.301177: Yayy! New best EMA pseudo Dice: 0.6603\n",
      "EarlyStopping: 5 / 100\n",
      "2024-12-15 15:13:56.197613: \n",
      "2024-12-15 15:13:56.198613: Epoch 19\n",
      "2024-12-15 15:13:56.203613: Current learning rate: 0.00983\n",
      "2024-12-15 15:14:53.856794: train_loss -0.3246\n",
      "2024-12-15 15:14:53.857499: val_loss -0.3222\n",
      "2024-12-15 15:14:53.864504: Pseudo dice [0.6675, 0.7885]\n",
      "2024-12-15 15:14:53.869525: Epoch time: 57.66 s\n",
      "2024-12-15 15:14:53.874525: Yayy! New best EMA pseudo Dice: 0.6671\n",
      "EarlyStopping: 6 / 100\n",
      "2024-12-15 15:14:54.867122: \n",
      "2024-12-15 15:14:54.867122: Epoch 20\n",
      "2024-12-15 15:14:54.874127: Current learning rate: 0.00982\n",
      "2024-12-15 15:15:51.437914: train_loss -0.3238\n",
      "2024-12-15 15:15:51.438915: val_loss -0.2355\n",
      "2024-12-15 15:15:51.445914: Pseudo dice [0.6844, 0.8117]\n",
      "2024-12-15 15:15:51.450916: Epoch time: 56.57 s\n",
      "2024-12-15 15:15:51.455917: Yayy! New best EMA pseudo Dice: 0.6752\n",
      "EarlyStopping: 7 / 100\n",
      "2024-12-15 15:15:52.341699: \n",
      "2024-12-15 15:15:52.341699: Epoch 21\n",
      "2024-12-15 15:15:52.347696: Current learning rate: 0.00981\n",
      "2024-12-15 15:16:48.827282: train_loss -0.2412\n",
      "2024-12-15 15:16:48.827282: val_loss -0.2427\n",
      "2024-12-15 15:16:48.835285: Pseudo dice [0.7015, 0.7078]\n",
      "2024-12-15 15:16:48.839283: Epoch time: 56.49 s\n",
      "2024-12-15 15:16:48.844282: Yayy! New best EMA pseudo Dice: 0.6781\n",
      "EarlyStopping: 8 / 100\n",
      "2024-12-15 15:16:49.888130: \n",
      "2024-12-15 15:16:49.889130: Epoch 22\n",
      "2024-12-15 15:16:49.894130: Current learning rate: 0.0098\n",
      "2024-12-15 15:17:46.380002: train_loss -0.2957\n",
      "2024-12-15 15:17:46.381002: val_loss -0.3257\n",
      "2024-12-15 15:17:46.388004: Pseudo dice [0.6953, 0.7936]\n",
      "2024-12-15 15:17:46.393003: Epoch time: 56.49 s\n",
      "2024-12-15 15:17:46.398001: Yayy! New best EMA pseudo Dice: 0.6848\n",
      "EarlyStopping: 9 / 100\n",
      "2024-12-15 15:17:47.242008: \n",
      "2024-12-15 15:17:47.242008: Epoch 23\n",
      "2024-12-15 15:17:47.248011: Current learning rate: 0.00979\n",
      "2024-12-15 15:18:43.734951: train_loss -0.3084\n",
      "2024-12-15 15:18:43.735951: val_loss -0.2943\n",
      "2024-12-15 15:18:43.742951: Pseudo dice [0.692, 0.6935]\n",
      "2024-12-15 15:18:43.747952: Epoch time: 56.49 s\n",
      "2024-12-15 15:18:43.752951: Yayy! New best EMA pseudo Dice: 0.6856\n",
      "EarlyStopping: 10 / 100\n",
      "2024-12-15 15:18:44.791210: \n",
      "2024-12-15 15:18:44.791210: Epoch 24\n",
      "2024-12-15 15:18:44.797208: Current learning rate: 0.00978\n",
      "2024-12-15 15:19:41.306394: train_loss -0.32\n",
      "2024-12-15 15:19:41.306394: val_loss -0.2846\n",
      "2024-12-15 15:19:41.313393: Pseudo dice [0.7154, 0.7912]\n",
      "2024-12-15 15:19:41.317439: Epoch time: 56.52 s\n",
      "2024-12-15 15:19:41.322438: Yayy! New best EMA pseudo Dice: 0.6923\n",
      "EarlyStopping: 11 / 100\n",
      "2024-12-15 15:19:42.195574: \n",
      "2024-12-15 15:19:42.195574: Epoch 25\n",
      "2024-12-15 15:19:42.200584: Current learning rate: 0.00977\n",
      "2024-12-15 15:20:38.693236: train_loss -0.3391\n",
      "2024-12-15 15:20:38.693236: val_loss -0.3037\n",
      "2024-12-15 15:20:38.700742: Pseudo dice [0.6956, 0.691]\n",
      "2024-12-15 15:20:38.705742: Epoch time: 56.5 s\n",
      "2024-12-15 15:20:38.710742: Yayy! New best EMA pseudo Dice: 0.6924\n",
      "EarlyStopping: 12 / 100\n",
      "2024-12-15 15:20:39.557020: \n",
      "2024-12-15 15:20:39.557020: Epoch 26\n",
      "2024-12-15 15:20:39.563020: Current learning rate: 0.00977\n",
      "2024-12-15 15:21:36.069758: train_loss -0.3174\n",
      "2024-12-15 15:21:36.070758: val_loss -0.2544\n",
      "2024-12-15 15:21:36.077757: Pseudo dice [0.6605, 0.7621]\n",
      "2024-12-15 15:21:36.081757: Epoch time: 56.51 s\n",
      "2024-12-15 15:21:36.086760: Yayy! New best EMA pseudo Dice: 0.6943\n",
      "EarlyStopping: 13 / 100\n",
      "2024-12-15 15:21:36.948896: \n",
      "2024-12-15 15:21:36.949897: Epoch 27\n",
      "2024-12-15 15:21:36.954900: Current learning rate: 0.00976\n",
      "2024-12-15 15:22:33.445489: train_loss -0.3222\n",
      "2024-12-15 15:22:33.446490: val_loss -0.2863\n",
      "2024-12-15 15:22:33.453487: Pseudo dice [0.6934, 0.7414]\n",
      "2024-12-15 15:22:33.458488: Epoch time: 56.5 s\n",
      "2024-12-15 15:22:33.463490: Yayy! New best EMA pseudo Dice: 0.6966\n",
      "EarlyStopping: 14 / 100\n",
      "2024-12-15 15:22:34.335142: \n",
      "2024-12-15 15:22:34.335142: Epoch 28\n",
      "2024-12-15 15:22:34.341142: Current learning rate: 0.00975\n",
      "2024-12-15 15:23:30.893739: train_loss -0.3494\n",
      "2024-12-15 15:23:30.894738: val_loss -0.3314\n",
      "2024-12-15 15:23:30.900736: Pseudo dice [0.6711, 0.7465]\n",
      "2024-12-15 15:23:30.905738: Epoch time: 56.56 s\n",
      "2024-12-15 15:23:30.910738: Yayy! New best EMA pseudo Dice: 0.6978\n",
      "EarlyStopping: 15 / 100\n",
      "2024-12-15 15:23:31.947345: \n",
      "2024-12-15 15:23:31.947345: Epoch 29\n",
      "2024-12-15 15:23:31.951345: Current learning rate: 0.00974\n",
      "2024-12-15 15:24:28.445780: train_loss -0.3377\n",
      "2024-12-15 15:24:28.446783: val_loss -0.2982\n",
      "2024-12-15 15:24:28.453781: Pseudo dice [0.6892, 0.7835]\n",
      "2024-12-15 15:24:28.458782: Epoch time: 56.5 s\n",
      "2024-12-15 15:24:28.463784: Yayy! New best EMA pseudo Dice: 0.7017\n",
      "EarlyStopping: 16 / 100\n",
      "2024-12-15 15:24:29.323280: \n",
      "2024-12-15 15:24:29.323280: Epoch 30\n",
      "2024-12-15 15:24:29.329281: Current learning rate: 0.00973\n",
      "2024-12-15 15:25:25.822650: train_loss -0.3579\n",
      "2024-12-15 15:25:25.822650: val_loss -0.3175\n",
      "2024-12-15 15:25:25.830695: Pseudo dice [0.688, 0.7556]\n",
      "2024-12-15 15:25:25.835695: Epoch time: 56.5 s\n",
      "2024-12-15 15:25:25.840693: Yayy! New best EMA pseudo Dice: 0.7037\n",
      "EarlyStopping: 17 / 100\n",
      "2024-12-15 15:25:26.733827: \n",
      "2024-12-15 15:25:26.733827: Epoch 31\n",
      "2024-12-15 15:25:26.738862: Current learning rate: 0.00972\n",
      "2024-12-15 15:26:23.851354: train_loss -0.3748\n",
      "2024-12-15 15:26:23.851354: val_loss -0.3604\n",
      "2024-12-15 15:26:23.860363: Pseudo dice [0.6945, 0.7735]\n",
      "2024-12-15 15:26:23.865372: Epoch time: 57.12 s\n",
      "2024-12-15 15:26:23.870376: Yayy! New best EMA pseudo Dice: 0.7067\n",
      "EarlyStopping: 18 / 100\n",
      "2024-12-15 15:26:24.726027: \n",
      "2024-12-15 15:26:24.727027: Epoch 32\n",
      "2024-12-15 15:26:24.732349: Current learning rate: 0.00971\n",
      "2024-12-15 15:27:21.615822: train_loss -0.3704\n",
      "2024-12-15 15:27:21.615822: val_loss -0.2964\n",
      "2024-12-15 15:27:21.623839: Pseudo dice [0.7356, 0.6656]\n",
      "2024-12-15 15:27:21.629344: Epoch time: 56.89 s\n",
      "EarlyStopping: 19 / 100\n",
      "2024-12-15 15:27:22.322680: \n",
      "2024-12-15 15:27:22.322680: Epoch 33\n",
      "2024-12-15 15:27:22.328185: Current learning rate: 0.0097\n",
      "2024-12-15 15:28:19.236700: train_loss -0.3781\n",
      "2024-12-15 15:28:19.237698: val_loss -0.3298\n",
      "2024-12-15 15:28:19.244711: Pseudo dice [0.7051, 0.7356]\n",
      "2024-12-15 15:28:19.250218: Epoch time: 56.92 s\n",
      "2024-12-15 15:28:19.254729: Yayy! New best EMA pseudo Dice: 0.7075\n",
      "EarlyStopping: 20 / 100\n",
      "2024-12-15 15:28:20.283768: \n",
      "2024-12-15 15:28:20.284767: Epoch 34\n",
      "2024-12-15 15:28:20.290275: Current learning rate: 0.00969\n",
      "2024-12-15 15:29:17.130984: train_loss -0.3769\n",
      "2024-12-15 15:29:17.131498: val_loss -0.3205\n",
      "2024-12-15 15:29:17.140048: Pseudo dice [0.7039, 0.5403]\n",
      "2024-12-15 15:29:17.145146: Epoch time: 56.85 s\n",
      "EarlyStopping: 21 / 100\n",
      "2024-12-15 15:29:17.836501: \n",
      "2024-12-15 15:29:17.836501: Epoch 35\n",
      "2024-12-15 15:29:17.841926: Current learning rate: 0.00968\n",
      "2024-12-15 15:30:15.227769: train_loss -0.3785\n",
      "2024-12-15 15:30:15.229273: val_loss -0.3181\n",
      "2024-12-15 15:30:15.236785: Pseudo dice [0.7261, 0.7239]\n",
      "2024-12-15 15:30:15.242801: Epoch time: 57.39 s\n",
      "EarlyStopping: 22 / 100\n",
      "2024-12-15 15:30:16.077338: \n",
      "2024-12-15 15:30:16.078337: Epoch 36\n",
      "2024-12-15 15:30:16.083384: Current learning rate: 0.00968\n",
      "2024-12-15 15:31:12.843481: train_loss -0.3816\n",
      "2024-12-15 15:31:12.843481: val_loss -0.2921\n",
      "2024-12-15 15:31:12.850784: Pseudo dice [0.7476, 0.7299]\n",
      "2024-12-15 15:31:12.855495: Epoch time: 56.77 s\n",
      "EarlyStopping: 23 / 100\n",
      "2024-12-15 15:31:13.555100: \n",
      "2024-12-15 15:31:13.556100: Epoch 37\n",
      "2024-12-15 15:31:13.561112: Current learning rate: 0.00967\n",
      "2024-12-15 15:32:10.321684: train_loss -0.3855\n",
      "2024-12-15 15:32:10.321684: val_loss -0.352\n",
      "2024-12-15 15:32:10.329188: Pseudo dice [0.7239, 0.7752]\n",
      "2024-12-15 15:32:10.334702: Epoch time: 56.77 s\n",
      "2024-12-15 15:32:10.339208: Yayy! New best EMA pseudo Dice: 0.7097\n",
      "EarlyStopping: 24 / 100\n",
      "2024-12-15 15:32:11.217697: \n",
      "2024-12-15 15:32:11.217697: Epoch 38\n",
      "2024-12-15 15:32:11.223551: Current learning rate: 0.00966\n",
      "2024-12-15 15:33:07.970335: train_loss -0.3839\n",
      "2024-12-15 15:33:07.970642: val_loss -0.3172\n",
      "2024-12-15 15:33:07.978343: Pseudo dice [0.7015, 0.7838]\n",
      "2024-12-15 15:33:07.983357: Epoch time: 56.75 s\n",
      "2024-12-15 15:33:07.987357: Yayy! New best EMA pseudo Dice: 0.713\n",
      "EarlyStopping: 25 / 100\n",
      "2024-12-15 15:33:08.871087: \n",
      "2024-12-15 15:33:08.872089: Epoch 39\n",
      "2024-12-15 15:33:08.877089: Current learning rate: 0.00965\n",
      "2024-12-15 15:34:05.656033: train_loss -0.4003\n",
      "2024-12-15 15:34:05.656033: val_loss -0.3111\n",
      "2024-12-15 15:34:05.664062: Pseudo dice [0.7223, 0.83]\n",
      "2024-12-15 15:34:05.668063: Epoch time: 56.78 s\n",
      "2024-12-15 15:34:05.673093: Yayy! New best EMA pseudo Dice: 0.7193\n",
      "EarlyStopping: 26 / 100\n",
      "2024-12-15 15:34:06.556946: \n",
      "2024-12-15 15:34:06.557949: Epoch 40\n",
      "2024-12-15 15:34:06.561968: Current learning rate: 0.00964\n",
      "2024-12-15 15:35:03.308390: train_loss -0.4019\n",
      "2024-12-15 15:35:03.309392: val_loss -0.3441\n",
      "2024-12-15 15:35:03.316408: Pseudo dice [0.7111, 0.8237]\n",
      "2024-12-15 15:35:03.321417: Epoch time: 56.75 s\n",
      "2024-12-15 15:35:03.326420: Yayy! New best EMA pseudo Dice: 0.7241\n",
      "EarlyStopping: 27 / 100\n",
      "2024-12-15 15:35:04.224035: \n",
      "2024-12-15 15:35:04.224035: Epoch 41\n",
      "2024-12-15 15:35:04.229033: Current learning rate: 0.00963\n",
      "2024-12-15 15:36:01.142213: train_loss -0.4026\n",
      "2024-12-15 15:36:01.143213: val_loss -0.3576\n",
      "2024-12-15 15:36:01.150217: Pseudo dice [0.7152, 0.7512]\n",
      "2024-12-15 15:36:01.155226: Epoch time: 56.92 s\n",
      "2024-12-15 15:36:01.160231: Yayy! New best EMA pseudo Dice: 0.7251\n",
      "EarlyStopping: 28 / 100\n",
      "2024-12-15 15:36:02.019515: \n",
      "2024-12-15 15:36:02.020027: Epoch 42\n",
      "2024-12-15 15:36:02.025519: Current learning rate: 0.00962\n",
      "2024-12-15 15:36:58.887432: train_loss -0.4073\n",
      "2024-12-15 15:36:58.887432: val_loss -0.3019\n",
      "2024-12-15 15:36:58.894937: Pseudo dice [0.7073, 0.7703]\n",
      "2024-12-15 15:36:58.898933: Epoch time: 56.87 s\n",
      "2024-12-15 15:36:58.904038: Yayy! New best EMA pseudo Dice: 0.7264\n",
      "EarlyStopping: 29 / 100\n",
      "2024-12-15 15:36:59.771511: \n",
      "2024-12-15 15:36:59.771511: Epoch 43\n",
      "2024-12-15 15:36:59.777515: Current learning rate: 0.00961\n",
      "2024-12-15 15:37:56.262875: train_loss -0.3972\n",
      "2024-12-15 15:37:56.262875: val_loss -0.3055\n",
      "2024-12-15 15:37:56.270875: Pseudo dice [0.7272, 0.7078]\n",
      "2024-12-15 15:37:56.275875: Epoch time: 56.49 s\n",
      "EarlyStopping: 30 / 100\n",
      "2024-12-15 15:37:57.239139: \n",
      "2024-12-15 15:37:57.239139: Epoch 44\n",
      "2024-12-15 15:37:57.246652: Current learning rate: 0.0096\n",
      "2024-12-15 15:38:53.722178: train_loss -0.4104\n",
      "2024-12-15 15:38:53.722178: val_loss -0.4032\n",
      "2024-12-15 15:38:53.729176: Pseudo dice [0.6649, 0.7962]\n",
      "2024-12-15 15:38:53.734178: Epoch time: 56.48 s\n",
      "EarlyStopping: 31 / 100\n",
      "2024-12-15 15:38:54.412473: \n",
      "2024-12-15 15:38:54.412473: Epoch 45\n",
      "2024-12-15 15:38:54.418471: Current learning rate: 0.00959\n",
      "2024-12-15 15:39:50.915422: train_loss -0.4344\n",
      "2024-12-15 15:39:50.915422: val_loss -0.3647\n",
      "2024-12-15 15:39:50.922927: Pseudo dice [0.6766, 0.6759]\n",
      "2024-12-15 15:39:50.927971: Epoch time: 56.5 s\n",
      "EarlyStopping: 32 / 100\n",
      "2024-12-15 15:39:51.598175: \n",
      "2024-12-15 15:39:51.599174: Epoch 46\n",
      "2024-12-15 15:39:51.604177: Current learning rate: 0.00959\n",
      "2024-12-15 15:40:48.450197: train_loss -0.4522\n",
      "2024-12-15 15:40:48.451197: val_loss -0.4126\n",
      "2024-12-15 15:40:48.458224: Pseudo dice [0.6778, 0.7371]\n",
      "2024-12-15 15:40:48.463225: Epoch time: 56.85 s\n",
      "EarlyStopping: 33 / 100\n",
      "2024-12-15 15:40:49.126268: \n",
      "2024-12-15 15:40:49.127272: Epoch 47\n",
      "2024-12-15 15:40:49.132272: Current learning rate: 0.00958\n",
      "2024-12-15 15:41:45.928601: train_loss -0.4621\n",
      "2024-12-15 15:41:45.929599: val_loss -0.4141\n",
      "2024-12-15 15:41:45.938114: Pseudo dice [0.7155, 0.8098]\n",
      "2024-12-15 15:41:45.943115: Epoch time: 56.8 s\n",
      "EarlyStopping: 34 / 100\n",
      "2024-12-15 15:41:46.608401: \n",
      "2024-12-15 15:41:46.608401: Epoch 48\n",
      "2024-12-15 15:41:46.613404: Current learning rate: 0.00957\n",
      "2024-12-15 15:42:43.363367: train_loss -0.4581\n",
      "2024-12-15 15:42:43.364368: val_loss -0.3768\n",
      "2024-12-15 15:42:43.370379: Pseudo dice [0.7037, 0.5488]\n",
      "2024-12-15 15:42:43.375406: Epoch time: 56.76 s\n",
      "EarlyStopping: 35 / 100\n",
      "2024-12-15 15:42:44.044003: \n",
      "2024-12-15 15:42:44.044003: Epoch 49\n",
      "2024-12-15 15:42:44.050026: Current learning rate: 0.00956\n",
      "2024-12-15 15:43:40.849013: train_loss -0.368\n",
      "2024-12-15 15:43:40.849013: val_loss -0.3065\n",
      "2024-12-15 15:43:40.857527: Pseudo dice [0.685, 0.7003]\n",
      "2024-12-15 15:43:40.862529: Epoch time: 56.81 s\n",
      "EarlyStopping: 36 / 100\n",
      "2024-12-15 15:43:41.713901: \n",
      "2024-12-15 15:43:41.713901: Epoch 50\n",
      "2024-12-15 15:43:41.719920: Current learning rate: 0.00955\n",
      "2024-12-15 15:44:38.472924: train_loss -0.4006\n",
      "2024-12-15 15:44:38.473927: val_loss -0.3955\n",
      "2024-12-15 15:44:38.480948: Pseudo dice [0.6558, 0.7392]\n",
      "2024-12-15 15:44:38.486454: Epoch time: 56.76 s\n",
      "EarlyStopping: 37 / 100\n",
      "2024-12-15 15:44:39.318534: \n",
      "2024-12-15 15:44:39.318534: Epoch 51\n",
      "2024-12-15 15:44:39.324040: Current learning rate: 0.00954\n",
      "2024-12-15 15:45:36.088202: train_loss -0.4018\n",
      "2024-12-15 15:45:36.089202: val_loss -0.3582\n",
      "2024-12-15 15:45:36.096511: Pseudo dice [0.6958, 0.725]\n",
      "2024-12-15 15:45:36.102220: Epoch time: 56.77 s\n",
      "EarlyStopping: 38 / 100\n",
      "2024-12-15 15:45:36.776839: \n",
      "2024-12-15 15:45:36.776839: Epoch 52\n",
      "2024-12-15 15:45:36.781844: Current learning rate: 0.00953\n",
      "2024-12-15 15:46:33.546784: train_loss -0.4291\n",
      "2024-12-15 15:46:33.547338: val_loss -0.4206\n",
      "2024-12-15 15:46:33.553847: Pseudo dice [0.7223, 0.7622]\n",
      "2024-12-15 15:46:33.558861: Epoch time: 56.77 s\n",
      "EarlyStopping: 39 / 100\n",
      "2024-12-15 15:46:34.238954: \n",
      "2024-12-15 15:46:34.238954: Epoch 53\n",
      "2024-12-15 15:46:34.243952: Current learning rate: 0.00952\n",
      "2024-12-15 15:47:31.010966: train_loss -0.4336\n",
      "2024-12-15 15:47:31.011967: val_loss -0.3954\n",
      "2024-12-15 15:47:31.019976: Pseudo dice [0.7132, 0.687]\n",
      "2024-12-15 15:47:31.023975: Epoch time: 56.77 s\n",
      "EarlyStopping: 40 / 100\n",
      "2024-12-15 15:47:31.876422: \n",
      "2024-12-15 15:47:31.876422: Epoch 54\n",
      "2024-12-15 15:47:31.881932: Current learning rate: 0.00951\n",
      "2024-12-15 15:48:28.631460: train_loss -0.469\n",
      "2024-12-15 15:48:28.632462: val_loss -0.4351\n",
      "2024-12-15 15:48:28.639474: Pseudo dice [0.7206, 0.7537]\n",
      "2024-12-15 15:48:28.643474: Epoch time: 56.76 s\n",
      "EarlyStopping: 41 / 100\n",
      "2024-12-15 15:48:29.323789: \n",
      "2024-12-15 15:48:29.323789: Epoch 55\n",
      "2024-12-15 15:48:29.328810: Current learning rate: 0.0095\n",
      "2024-12-15 15:49:26.108031: train_loss -0.4621\n",
      "2024-12-15 15:49:26.109031: val_loss -0.4233\n",
      "2024-12-15 15:49:26.115536: Pseudo dice [0.6825, 0.7471]\n",
      "2024-12-15 15:49:26.121051: Epoch time: 56.78 s\n",
      "EarlyStopping: 42 / 100\n",
      "2024-12-15 15:49:26.799371: \n",
      "2024-12-15 15:49:26.799371: Epoch 56\n",
      "2024-12-15 15:49:26.805370: Current learning rate: 0.00949\n",
      "2024-12-15 15:50:23.770998: train_loss -0.483\n",
      "2024-12-15 15:50:23.771998: val_loss -0.3914\n",
      "2024-12-15 15:50:23.779000: Pseudo dice [0.7411, 0.773]\n",
      "2024-12-15 15:50:23.783998: Epoch time: 56.97 s\n",
      "EarlyStopping: 43 / 100\n",
      "2024-12-15 15:50:24.472275: \n",
      "2024-12-15 15:50:24.472275: Epoch 57\n",
      "2024-12-15 15:50:24.478276: Current learning rate: 0.00949\n",
      "2024-12-15 15:51:20.967064: train_loss -0.4753\n",
      "2024-12-15 15:51:20.967064: val_loss -0.3953\n",
      "2024-12-15 15:51:20.974068: Pseudo dice [0.724, 0.7556]\n",
      "2024-12-15 15:51:20.979067: Epoch time: 56.5 s\n",
      "EarlyStopping: 44 / 100\n",
      "2024-12-15 15:51:21.653312: \n",
      "2024-12-15 15:51:21.654311: Epoch 58\n",
      "2024-12-15 15:51:21.658311: Current learning rate: 0.00948\n",
      "2024-12-15 15:52:18.180022: train_loss -0.484\n",
      "2024-12-15 15:52:18.181022: val_loss -0.3174\n",
      "2024-12-15 15:52:18.189022: Pseudo dice [0.6856, 0.6838]\n",
      "2024-12-15 15:52:18.195022: Epoch time: 56.53 s\n",
      "EarlyStopping: 45 / 100\n",
      "2024-12-15 15:52:19.017742: \n",
      "2024-12-15 15:52:19.018742: Epoch 59\n",
      "2024-12-15 15:52:19.022744: Current learning rate: 0.00947\n",
      "2024-12-15 15:53:15.481590: train_loss -0.4707\n",
      "2024-12-15 15:53:15.482590: val_loss -0.3814\n",
      "2024-12-15 15:53:15.489096: Pseudo dice [0.6927, 0.7827]\n",
      "2024-12-15 15:53:15.494096: Epoch time: 56.46 s\n",
      "EarlyStopping: 46 / 100\n",
      "2024-12-15 15:53:16.198236: \n",
      "2024-12-15 15:53:16.199236: Epoch 60\n",
      "2024-12-15 15:53:16.205238: Current learning rate: 0.00946\n",
      "2024-12-15 15:54:12.680532: train_loss -0.4757\n",
      "2024-12-15 15:54:12.680532: val_loss -0.4269\n",
      "2024-12-15 15:54:12.687576: Pseudo dice [0.7312, 0.7802]\n",
      "2024-12-15 15:54:12.692575: Epoch time: 56.48 s\n",
      "EarlyStopping: 47 / 100\n",
      "2024-12-15 15:54:13.379339: \n",
      "2024-12-15 15:54:13.379339: Epoch 61\n",
      "2024-12-15 15:54:13.385339: Current learning rate: 0.00945\n",
      "2024-12-15 15:55:09.844182: train_loss -0.4962\n",
      "2024-12-15 15:55:09.845183: val_loss -0.4207\n",
      "2024-12-15 15:55:09.853183: Pseudo dice [0.7286, 0.8085]\n",
      "2024-12-15 15:55:09.858182: Epoch time: 56.47 s\n",
      "2024-12-15 15:55:09.863185: Yayy! New best EMA pseudo Dice: 0.7277\n",
      "EarlyStopping: 48 / 100\n",
      "2024-12-15 15:55:10.746195: \n",
      "2024-12-15 15:55:10.747206: Epoch 62\n",
      "2024-12-15 15:55:10.752194: Current learning rate: 0.00944\n",
      "2024-12-15 15:56:07.236944: train_loss -0.4811\n",
      "2024-12-15 15:56:07.236944: val_loss -0.3919\n",
      "2024-12-15 15:56:07.244944: Pseudo dice [0.7248, 0.7675]\n",
      "2024-12-15 15:56:07.249944: Epoch time: 56.49 s\n",
      "2024-12-15 15:56:07.254944: Yayy! New best EMA pseudo Dice: 0.7295\n",
      "EarlyStopping: 49 / 100\n",
      "2024-12-15 15:56:08.134140: \n",
      "2024-12-15 15:56:08.134140: Epoch 63\n",
      "2024-12-15 15:56:08.139143: Current learning rate: 0.00943\n",
      "2024-12-15 15:57:04.585910: train_loss -0.4909\n",
      "2024-12-15 15:57:04.586910: val_loss -0.4404\n",
      "2024-12-15 15:57:04.594912: Pseudo dice [0.6955, 0.7898]\n",
      "2024-12-15 15:57:04.599912: Epoch time: 56.45 s\n",
      "2024-12-15 15:57:04.604910: Yayy! New best EMA pseudo Dice: 0.7308\n",
      "EarlyStopping: 50 / 100\n",
      "2024-12-15 15:57:05.649344: \n",
      "2024-12-15 15:57:05.650344: Epoch 64\n",
      "2024-12-15 15:57:05.655345: Current learning rate: 0.00942\n",
      "2024-12-15 15:58:02.130224: train_loss -0.4851\n",
      "2024-12-15 15:58:02.131225: val_loss -0.4066\n",
      "2024-12-15 15:58:02.138224: Pseudo dice [0.7302, 0.6165]\n",
      "2024-12-15 15:58:02.143223: Epoch time: 56.48 s\n",
      "EarlyStopping: 51 / 100\n",
      "2024-12-15 15:58:02.845227: \n",
      "2024-12-15 15:58:02.846228: Epoch 65\n",
      "2024-12-15 15:58:02.851225: Current learning rate: 0.00941\n",
      "2024-12-15 15:58:59.361834: train_loss -0.4975\n",
      "2024-12-15 15:58:59.361834: val_loss -0.4183\n",
      "2024-12-15 15:58:59.369834: Pseudo dice [0.7252, 0.8246]\n",
      "2024-12-15 15:58:59.374834: Epoch time: 56.52 s\n",
      "EarlyStopping: 52 / 100\n",
      "2024-12-15 15:59:00.196423: \n",
      "2024-12-15 15:59:00.197421: Epoch 66\n",
      "2024-12-15 15:59:00.202420: Current learning rate: 0.0094\n",
      "2024-12-15 15:59:56.862932: train_loss -0.4941\n",
      "2024-12-15 15:59:56.862932: val_loss -0.4273\n",
      "2024-12-15 15:59:56.870941: Pseudo dice [0.712, 0.8229]\n",
      "2024-12-15 15:59:56.875940: Epoch time: 56.67 s\n",
      "2024-12-15 15:59:56.879954: Yayy! New best EMA pseudo Dice: 0.7338\n",
      "EarlyStopping: 53 / 100\n",
      "2024-12-15 15:59:57.759217: \n",
      "2024-12-15 15:59:57.760218: Epoch 67\n",
      "2024-12-15 15:59:57.766216: Current learning rate: 0.00939\n",
      "2024-12-15 16:00:54.547269: train_loss -0.4688\n",
      "2024-12-15 16:00:54.547269: val_loss -0.4398\n",
      "2024-12-15 16:00:54.554785: Pseudo dice [0.7273, 0.8164]\n",
      "2024-12-15 16:00:54.560819: Epoch time: 56.79 s\n",
      "2024-12-15 16:00:54.565819: Yayy! New best EMA pseudo Dice: 0.7376\n",
      "EarlyStopping: 54 / 100\n",
      "2024-12-15 16:00:55.451169: \n",
      "2024-12-15 16:00:55.452170: Epoch 68\n",
      "2024-12-15 16:00:55.457676: Current learning rate: 0.00939\n",
      "2024-12-15 16:01:52.239890: train_loss -0.488\n",
      "2024-12-15 16:01:52.240891: val_loss -0.4427\n",
      "2024-12-15 16:01:52.247903: Pseudo dice [0.7301, 0.828]\n",
      "2024-12-15 16:01:52.252914: Epoch time: 56.79 s\n",
      "2024-12-15 16:01:52.256912: Yayy! New best EMA pseudo Dice: 0.7418\n",
      "EarlyStopping: 55 / 100\n",
      "2024-12-15 16:01:53.145478: \n",
      "2024-12-15 16:01:53.145478: Epoch 69\n",
      "2024-12-15 16:01:53.151498: Current learning rate: 0.00938\n",
      "2024-12-15 16:02:49.912097: train_loss -0.4992\n",
      "2024-12-15 16:02:49.913100: val_loss -0.3887\n",
      "2024-12-15 16:02:49.920114: Pseudo dice [0.7328, 0.773]\n",
      "2024-12-15 16:02:49.924114: Epoch time: 56.77 s\n",
      "2024-12-15 16:02:49.929129: Yayy! New best EMA pseudo Dice: 0.7429\n",
      "EarlyStopping: 56 / 100\n",
      "2024-12-15 16:02:50.815444: \n",
      "2024-12-15 16:02:50.815444: Epoch 70\n",
      "2024-12-15 16:02:50.821281: Current learning rate: 0.00937\n",
      "2024-12-15 16:03:47.584533: train_loss -0.5005\n",
      "2024-12-15 16:03:47.585534: val_loss -0.4106\n",
      "2024-12-15 16:03:47.591554: Pseudo dice [0.7125, 0.8049]\n",
      "2024-12-15 16:03:47.597061: Epoch time: 56.77 s\n",
      "2024-12-15 16:03:47.602088: Yayy! New best EMA pseudo Dice: 0.7445\n",
      "EarlyStopping: 57 / 100\n",
      "2024-12-15 16:03:48.483594: \n",
      "2024-12-15 16:03:48.484592: Epoch 71\n",
      "2024-12-15 16:03:48.489620: Current learning rate: 0.00936\n",
      "2024-12-15 16:04:45.274123: train_loss -0.5096\n",
      "2024-12-15 16:04:45.275123: val_loss -0.4375\n",
      "2024-12-15 16:04:45.282138: Pseudo dice [0.716, 0.7495]\n",
      "2024-12-15 16:04:45.287137: Epoch time: 56.79 s\n",
      "EarlyStopping: 58 / 100\n",
      "2024-12-15 16:04:45.989989: \n",
      "2024-12-15 16:04:45.989989: Epoch 72\n",
      "2024-12-15 16:04:45.994991: Current learning rate: 0.00935\n",
      "2024-12-15 16:05:42.771229: train_loss -0.5104\n",
      "2024-12-15 16:05:42.771229: val_loss -0.4214\n",
      "2024-12-15 16:05:42.779237: Pseudo dice [0.7239, 0.8241]\n",
      "2024-12-15 16:05:42.784242: Epoch time: 56.78 s\n",
      "2024-12-15 16:05:42.789258: Yayy! New best EMA pseudo Dice: 0.7464\n",
      "EarlyStopping: 59 / 100\n",
      "2024-12-15 16:05:43.878165: \n",
      "2024-12-15 16:05:43.878165: Epoch 73\n",
      "2024-12-15 16:05:43.882941: Current learning rate: 0.00934\n",
      "2024-12-15 16:06:40.628521: train_loss -0.5132\n",
      "2024-12-15 16:06:40.629217: val_loss -0.3951\n",
      "2024-12-15 16:06:40.636221: Pseudo dice [0.7163, 0.8341]\n",
      "2024-12-15 16:06:40.641235: Epoch time: 56.75 s\n",
      "2024-12-15 16:06:40.645235: Yayy! New best EMA pseudo Dice: 0.7492\n",
      "EarlyStopping: 60 / 100\n",
      "2024-12-15 16:06:41.717170: \n",
      "2024-12-15 16:06:41.717170: Epoch 74\n",
      "2024-12-15 16:06:41.723182: Current learning rate: 0.00933\n",
      "2024-12-15 16:07:38.485246: train_loss -0.5064\n",
      "2024-12-15 16:07:38.485246: val_loss -0.4199\n",
      "2024-12-15 16:07:38.493259: Pseudo dice [0.714, 0.8162]\n",
      "2024-12-15 16:07:38.497760: Epoch time: 56.77 s\n",
      "2024-12-15 16:07:38.502273: Yayy! New best EMA pseudo Dice: 0.7508\n",
      "EarlyStopping: 61 / 100\n",
      "2024-12-15 16:07:39.395820: \n",
      "2024-12-15 16:07:39.397323: Epoch 75\n",
      "2024-12-15 16:07:39.401839: Current learning rate: 0.00932\n",
      "2024-12-15 16:08:36.172856: train_loss -0.488\n",
      "2024-12-15 16:08:36.172856: val_loss -0.4126\n",
      "2024-12-15 16:08:36.179873: Pseudo dice [0.7163, 0.7165]\n",
      "2024-12-15 16:08:36.184873: Epoch time: 56.78 s\n",
      "EarlyStopping: 62 / 100\n",
      "2024-12-15 16:08:36.889038: \n",
      "2024-12-15 16:08:36.889038: Epoch 76\n",
      "2024-12-15 16:08:36.895041: Current learning rate: 0.00931\n",
      "2024-12-15 16:09:33.709781: train_loss -0.4719\n",
      "2024-12-15 16:09:33.709781: val_loss -0.3484\n",
      "2024-12-15 16:09:33.717791: Pseudo dice [0.701, 0.7505]\n",
      "2024-12-15 16:09:33.723799: Epoch time: 56.82 s\n",
      "EarlyStopping: 63 / 100\n",
      "2024-12-15 16:09:34.460126: \n",
      "2024-12-15 16:09:34.460126: Epoch 77\n",
      "2024-12-15 16:09:34.466126: Current learning rate: 0.0093\n",
      "2024-12-15 16:10:31.190177: train_loss -0.4737\n",
      "2024-12-15 16:10:31.190177: val_loss -0.4225\n",
      "2024-12-15 16:10:31.198177: Pseudo dice [0.6912, 0.8159]\n",
      "2024-12-15 16:10:31.203177: Epoch time: 56.73 s\n",
      "EarlyStopping: 64 / 100\n",
      "2024-12-15 16:10:31.910408: \n",
      "2024-12-15 16:10:31.911409: Epoch 78\n",
      "2024-12-15 16:10:31.916407: Current learning rate: 0.0093\n",
      "2024-12-15 16:11:28.436325: train_loss -0.4708\n",
      "2024-12-15 16:11:28.437327: val_loss -0.3613\n",
      "2024-12-15 16:11:28.444324: Pseudo dice [0.7083, 0.7303]\n",
      "2024-12-15 16:11:28.448325: Epoch time: 56.53 s\n",
      "EarlyStopping: 65 / 100\n",
      "2024-12-15 16:11:29.152475: \n",
      "2024-12-15 16:11:29.152990: Epoch 79\n",
      "2024-12-15 16:11:29.158070: Current learning rate: 0.00929\n",
      "2024-12-15 16:12:25.663179: train_loss -0.4775\n",
      "2024-12-15 16:12:25.664180: val_loss -0.3752\n",
      "2024-12-15 16:12:25.672179: Pseudo dice [0.7032, 0.7155]\n",
      "2024-12-15 16:12:25.676178: Epoch time: 56.51 s\n",
      "EarlyStopping: 66 / 100\n",
      "2024-12-15 16:12:26.393761: \n",
      "2024-12-15 16:12:26.393761: Epoch 80\n",
      "2024-12-15 16:12:26.398760: Current learning rate: 0.00928\n",
      "2024-12-15 16:13:22.882523: train_loss -0.4836\n",
      "2024-12-15 16:13:22.883523: val_loss -0.424\n",
      "2024-12-15 16:13:22.890521: Pseudo dice [0.6966, 0.7794]\n",
      "2024-12-15 16:13:22.895522: Epoch time: 56.49 s\n",
      "EarlyStopping: 67 / 100\n",
      "2024-12-15 16:13:23.747076: \n",
      "2024-12-15 16:13:23.747076: Epoch 81\n",
      "2024-12-15 16:13:23.752084: Current learning rate: 0.00927\n",
      "2024-12-15 16:14:20.243947: train_loss -0.5003\n",
      "2024-12-15 16:14:20.243947: val_loss -0.4241\n",
      "2024-12-15 16:14:20.252948: Pseudo dice [0.6994, 0.8051]\n",
      "2024-12-15 16:14:20.258947: Epoch time: 56.5 s\n",
      "EarlyStopping: 68 / 100\n",
      "2024-12-15 16:14:20.964361: \n",
      "2024-12-15 16:14:20.965361: Epoch 82\n",
      "2024-12-15 16:14:20.970361: Current learning rate: 0.00926\n",
      "2024-12-15 16:15:17.430409: train_loss -0.4917\n",
      "2024-12-15 16:15:17.431408: val_loss -0.4174\n",
      "2024-12-15 16:15:17.438409: Pseudo dice [0.7159, 0.7341]\n",
      "2024-12-15 16:15:17.444409: Epoch time: 56.47 s\n",
      "EarlyStopping: 69 / 100\n",
      "2024-12-15 16:15:18.118290: \n",
      "2024-12-15 16:15:18.118290: Epoch 83\n",
      "2024-12-15 16:15:18.124290: Current learning rate: 0.00925\n",
      "2024-12-15 16:16:14.584388: train_loss -0.4906\n",
      "2024-12-15 16:16:14.585390: val_loss -0.4275\n",
      "2024-12-15 16:16:14.592390: Pseudo dice [0.7129, 0.802]\n",
      "2024-12-15 16:16:14.598388: Epoch time: 56.47 s\n",
      "EarlyStopping: 70 / 100\n",
      "2024-12-15 16:16:15.441272: \n",
      "2024-12-15 16:16:15.441272: Epoch 84\n",
      "2024-12-15 16:16:15.447273: Current learning rate: 0.00924\n",
      "2024-12-15 16:17:11.906292: train_loss -0.506\n",
      "2024-12-15 16:17:11.907292: val_loss -0.4481\n",
      "2024-12-15 16:17:11.914340: Pseudo dice [0.7221, 0.8312]\n",
      "2024-12-15 16:17:11.918340: Epoch time: 56.47 s\n",
      "EarlyStopping: 71 / 100\n",
      "2024-12-15 16:17:12.600178: \n",
      "2024-12-15 16:17:12.600178: Epoch 85\n",
      "2024-12-15 16:17:12.606180: Current learning rate: 0.00923\n",
      "2024-12-15 16:18:09.101234: train_loss -0.4947\n",
      "2024-12-15 16:18:09.102234: val_loss -0.4317\n",
      "2024-12-15 16:18:09.108280: Pseudo dice [0.7193, 0.7774]\n",
      "2024-12-15 16:18:09.113283: Epoch time: 56.5 s\n",
      "EarlyStopping: 72 / 100\n",
      "2024-12-15 16:18:09.791285: \n",
      "2024-12-15 16:18:09.792284: Epoch 86\n",
      "2024-12-15 16:18:09.796284: Current learning rate: 0.00922\n",
      "2024-12-15 16:19:06.290142: train_loss -0.4897\n",
      "2024-12-15 16:19:06.290142: val_loss -0.4232\n",
      "2024-12-15 16:19:06.297481: Pseudo dice [0.7308, 0.7873]\n",
      "2024-12-15 16:19:06.302158: Epoch time: 56.5 s\n",
      "EarlyStopping: 73 / 100\n",
      "2024-12-15 16:19:06.995296: \n",
      "2024-12-15 16:19:06.995296: Epoch 87\n",
      "2024-12-15 16:19:07.000304: Current learning rate: 0.00921\n",
      "2024-12-15 16:20:03.482538: train_loss -0.4985\n",
      "2024-12-15 16:20:03.483538: val_loss -0.4541\n",
      "2024-12-15 16:20:03.489537: Pseudo dice [0.7123, 0.8087]\n",
      "2024-12-15 16:20:03.494672: Epoch time: 56.49 s\n",
      "EarlyStopping: 74 / 100\n",
      "2024-12-15 16:20:04.294358: \n",
      "2024-12-15 16:20:04.294358: Epoch 88\n",
      "2024-12-15 16:20:04.300357: Current learning rate: 0.0092\n",
      "2024-12-15 16:21:00.746643: train_loss -0.5077\n",
      "2024-12-15 16:21:00.746643: val_loss -0.4463\n",
      "2024-12-15 16:21:00.753644: Pseudo dice [0.7022, 0.7179]\n",
      "2024-12-15 16:21:00.758643: Epoch time: 56.45 s\n",
      "EarlyStopping: 75 / 100\n",
      "2024-12-15 16:21:01.452065: \n",
      "2024-12-15 16:21:01.452065: Epoch 89\n",
      "2024-12-15 16:21:01.458116: Current learning rate: 0.0092\n",
      "2024-12-15 16:21:57.921592: train_loss -0.4721\n",
      "2024-12-15 16:21:57.922593: val_loss -0.4164\n",
      "2024-12-15 16:21:57.929597: Pseudo dice [0.75, 0.7542]\n",
      "2024-12-15 16:21:57.935598: Epoch time: 56.47 s\n",
      "EarlyStopping: 76 / 100\n",
      "2024-12-15 16:21:58.614612: \n",
      "2024-12-15 16:21:58.614612: Epoch 90\n",
      "2024-12-15 16:21:58.619614: Current learning rate: 0.00919\n",
      "2024-12-15 16:22:55.095122: train_loss -0.494\n",
      "2024-12-15 16:22:55.095122: val_loss -0.4515\n",
      "2024-12-15 16:22:55.103122: Pseudo dice [0.7342, 0.8299]\n",
      "2024-12-15 16:22:55.108122: Epoch time: 56.48 s\n",
      "EarlyStopping: 77 / 100\n",
      "2024-12-15 16:22:55.787404: \n",
      "2024-12-15 16:22:55.787404: Epoch 91\n",
      "2024-12-15 16:22:55.793492: Current learning rate: 0.00918\n",
      "2024-12-15 16:23:52.464797: train_loss -0.4663\n",
      "2024-12-15 16:23:52.466299: val_loss -0.4232\n",
      "2024-12-15 16:23:52.472815: Pseudo dice [0.7009, 0.7402]\n",
      "2024-12-15 16:23:52.477831: Epoch time: 56.68 s\n",
      "EarlyStopping: 78 / 100\n",
      "2024-12-15 16:23:53.156435: \n",
      "2024-12-15 16:23:53.156941: Epoch 92\n",
      "2024-12-15 16:23:53.161946: Current learning rate: 0.00917\n",
      "2024-12-15 16:24:49.884959: train_loss -0.4791\n",
      "2024-12-15 16:24:49.884959: val_loss -0.4167\n",
      "2024-12-15 16:24:49.892983: Pseudo dice [0.7075, 0.8092]\n",
      "2024-12-15 16:24:49.899038: Epoch time: 56.73 s\n",
      "EarlyStopping: 79 / 100\n",
      "2024-12-15 16:24:50.576220: \n",
      "2024-12-15 16:24:50.576220: Epoch 93\n",
      "2024-12-15 16:24:50.582179: Current learning rate: 0.00916\n",
      "2024-12-15 16:25:47.332383: train_loss -0.4938\n",
      "2024-12-15 16:25:47.332383: val_loss -0.4099\n",
      "2024-12-15 16:25:47.340429: Pseudo dice [0.7518, 0.7841]\n",
      "2024-12-15 16:25:47.345428: Epoch time: 56.76 s\n",
      "EarlyStopping: 80 / 100\n",
      "2024-12-15 16:25:48.202271: \n",
      "2024-12-15 16:25:48.203271: Epoch 94\n",
      "2024-12-15 16:25:48.209057: Current learning rate: 0.00915\n",
      "2024-12-15 16:26:44.967342: train_loss -0.4967\n",
      "2024-12-15 16:26:44.967342: val_loss -0.3946\n",
      "2024-12-15 16:26:44.974351: Pseudo dice [0.7366, 0.7975]\n",
      "2024-12-15 16:26:44.979363: Epoch time: 56.77 s\n",
      "2024-12-15 16:26:44.983363: Yayy! New best EMA pseudo Dice: 0.751\n",
      "EarlyStopping: 81 / 100\n",
      "2024-12-15 16:26:46.040964: \n",
      "2024-12-15 16:26:46.040964: Epoch 95\n",
      "2024-12-15 16:26:46.046466: Current learning rate: 0.00914\n",
      "2024-12-15 16:27:42.792771: train_loss -0.5028\n",
      "2024-12-15 16:27:42.792771: val_loss -0.4094\n",
      "2024-12-15 16:27:42.801296: Pseudo dice [0.703, 0.8021]\n",
      "2024-12-15 16:27:42.806296: Epoch time: 56.75 s\n",
      "2024-12-15 16:27:42.810309: Yayy! New best EMA pseudo Dice: 0.7511\n",
      "EarlyStopping: 82 / 100\n",
      "2024-12-15 16:27:43.665553: \n",
      "2024-12-15 16:27:43.665553: Epoch 96\n",
      "2024-12-15 16:27:43.671061: Current learning rate: 0.00913\n",
      "2024-12-15 16:28:40.419782: train_loss -0.5008\n",
      "2024-12-15 16:28:40.420783: val_loss -0.4228\n",
      "2024-12-15 16:28:40.427787: Pseudo dice [0.7006, 0.7967]\n",
      "2024-12-15 16:28:40.432791: Epoch time: 56.76 s\n",
      "EarlyStopping: 83 / 100\n",
      "2024-12-15 16:28:41.119120: \n",
      "2024-12-15 16:28:41.119120: Epoch 97\n",
      "2024-12-15 16:28:41.124120: Current learning rate: 0.00912\n",
      "2024-12-15 16:29:37.881376: train_loss -0.5069\n",
      "2024-12-15 16:29:37.882376: val_loss -0.4314\n",
      "2024-12-15 16:29:37.890388: Pseudo dice [0.7182, 0.8278]\n",
      "2024-12-15 16:29:37.895390: Epoch time: 56.76 s\n",
      "2024-12-15 16:29:37.899404: Yayy! New best EMA pseudo Dice: 0.7531\n",
      "EarlyStopping: 84 / 100\n",
      "2024-12-15 16:29:38.764298: \n",
      "2024-12-15 16:29:38.765296: Epoch 98\n",
      "2024-12-15 16:29:38.770311: Current learning rate: 0.00911\n",
      "2024-12-15 16:30:35.541053: train_loss -0.5036\n",
      "2024-12-15 16:30:35.541053: val_loss -0.3563\n",
      "2024-12-15 16:30:35.551067: Pseudo dice [0.7106, 0.6985]\n",
      "2024-12-15 16:30:35.558073: Epoch time: 56.78 s\n",
      "EarlyStopping: 85 / 100\n",
      "2024-12-15 16:30:36.235312: \n",
      "2024-12-15 16:30:36.235312: Epoch 99\n",
      "2024-12-15 16:30:36.241326: Current learning rate: 0.0091\n",
      "2024-12-15 16:31:32.982222: train_loss -0.5148\n",
      "2024-12-15 16:31:32.983222: val_loss -0.4065\n",
      "2024-12-15 16:31:32.991236: Pseudo dice [0.7127, 0.8083]\n",
      "2024-12-15 16:31:32.997243: Epoch time: 56.75 s\n",
      "EarlyStopping: 86 / 100\n",
      "2024-12-15 16:31:33.862424: \n",
      "2024-12-15 16:31:33.862424: Epoch 100\n",
      "2024-12-15 16:31:33.867972: Current learning rate: 0.0091\n",
      "2024-12-15 16:32:30.607583: train_loss -0.5232\n",
      "2024-12-15 16:32:30.607583: val_loss -0.4394\n",
      "2024-12-15 16:32:30.614297: Pseudo dice [0.7024, 0.8123]\n",
      "2024-12-15 16:32:30.619307: Epoch time: 56.75 s\n",
      "EarlyStopping: 87 / 100\n",
      "2024-12-15 16:32:31.302585: \n",
      "2024-12-15 16:32:31.302585: Epoch 101\n",
      "2024-12-15 16:32:31.308145: Current learning rate: 0.00909\n",
      "2024-12-15 16:33:28.068067: train_loss -0.5227\n",
      "2024-12-15 16:33:28.068067: val_loss -0.4078\n",
      "2024-12-15 16:33:28.076070: Pseudo dice [0.6992, 0.7467]\n",
      "2024-12-15 16:33:28.081085: Epoch time: 56.77 s\n",
      "EarlyStopping: 88 / 100\n",
      "2024-12-15 16:33:28.764369: \n",
      "2024-12-15 16:33:28.764369: Epoch 102\n",
      "2024-12-15 16:33:28.769706: Current learning rate: 0.00908\n",
      "2024-12-15 16:34:25.551429: train_loss -0.5287\n",
      "2024-12-15 16:34:25.551429: val_loss -0.4524\n",
      "2024-12-15 16:34:25.558935: Pseudo dice [0.7204, 0.8026]\n",
      "2024-12-15 16:34:25.562935: Epoch time: 56.79 s\n",
      "EarlyStopping: 89 / 100\n",
      "2024-12-15 16:34:26.373403: \n",
      "2024-12-15 16:34:26.374403: Epoch 103\n",
      "2024-12-15 16:34:26.379418: Current learning rate: 0.00907\n",
      "2024-12-15 16:35:23.129200: train_loss -0.5198\n",
      "2024-12-15 16:35:23.129200: val_loss -0.4427\n",
      "2024-12-15 16:35:23.137206: Pseudo dice [0.7271, 0.8268]\n",
      "2024-12-15 16:35:23.142214: Epoch time: 56.75 s\n",
      "EarlyStopping: 90 / 100\n",
      "2024-12-15 16:35:24.004161: \n",
      "2024-12-15 16:35:24.004161: Epoch 104\n",
      "2024-12-15 16:35:24.010656: Current learning rate: 0.00906\n",
      "2024-12-15 16:36:20.756270: train_loss -0.5754\n",
      "2024-12-15 16:36:20.756773: val_loss -0.478\n",
      "2024-12-15 16:36:20.764283: Pseudo dice [0.6622, 0.6928]\n",
      "2024-12-15 16:36:20.769295: Epoch time: 56.75 s\n",
      "EarlyStopping: 91 / 100\n",
      "2024-12-15 16:36:21.453301: \n",
      "2024-12-15 16:36:21.453301: Epoch 105\n",
      "2024-12-15 16:36:21.458678: Current learning rate: 0.00905\n",
      "2024-12-15 16:37:18.214972: train_loss -0.4581\n",
      "2024-12-15 16:37:18.214972: val_loss -0.2787\n",
      "2024-12-15 16:37:18.223994: Pseudo dice [0.6244, 0.3379]\n",
      "2024-12-15 16:37:18.229008: Epoch time: 56.76 s\n",
      "EarlyStopping: 92 / 100\n",
      "2024-12-15 16:37:18.932205: \n",
      "2024-12-15 16:37:18.933208: Epoch 106\n",
      "2024-12-15 16:37:18.938216: Current learning rate: 0.00904\n",
      "2024-12-15 16:38:15.683758: train_loss -0.4524\n",
      "2024-12-15 16:38:15.683758: val_loss -0.4073\n",
      "2024-12-15 16:38:15.691783: Pseudo dice [0.703, 0.5506]\n",
      "2024-12-15 16:38:15.696287: Epoch time: 56.75 s\n",
      "EarlyStopping: 93 / 100\n",
      "2024-12-15 16:38:16.384707: \n",
      "2024-12-15 16:38:16.384707: Epoch 107\n",
      "2024-12-15 16:38:16.389731: Current learning rate: 0.00903\n",
      "2024-12-15 16:39:13.159994: train_loss -0.423\n",
      "2024-12-15 16:39:13.160996: val_loss -0.3528\n",
      "2024-12-15 16:39:13.168014: Pseudo dice [0.6385, 0.4351]\n",
      "2024-12-15 16:39:13.173018: Epoch time: 56.78 s\n",
      "EarlyStopping: 94 / 100\n",
      "2024-12-15 16:39:13.862283: \n",
      "2024-12-15 16:39:13.863281: Epoch 108\n",
      "2024-12-15 16:39:13.868597: Current learning rate: 0.00902\n",
      "2024-12-15 16:40:10.604344: train_loss -0.4055\n",
      "2024-12-15 16:40:10.604344: val_loss -0.4732\n",
      "2024-12-15 16:40:10.612355: Pseudo dice [0.6813, 0.4091]\n",
      "2024-12-15 16:40:10.617664: Epoch time: 56.74 s\n",
      "EarlyStopping: 95 / 100\n",
      "2024-12-15 16:40:11.303658: \n",
      "2024-12-15 16:40:11.303658: Epoch 109\n",
      "2024-12-15 16:40:11.309191: Current learning rate: 0.00901\n",
      "2024-12-15 16:41:08.029735: train_loss -0.4601\n",
      "2024-12-15 16:41:08.030734: val_loss -0.3863\n",
      "2024-12-15 16:41:08.037740: Pseudo dice [0.6823, 0.4586]\n",
      "2024-12-15 16:41:08.042743: Epoch time: 56.73 s\n",
      "EarlyStopping: 96 / 100\n",
      "2024-12-15 16:41:08.731616: \n",
      "2024-12-15 16:41:08.731616: Epoch 110\n",
      "2024-12-15 16:41:08.737442: Current learning rate: 0.009\n",
      "2024-12-15 16:42:05.483382: train_loss -0.3455\n",
      "2024-12-15 16:42:05.484382: val_loss -0.3977\n",
      "2024-12-15 16:42:05.491396: Pseudo dice [0.6329, 0.5166]\n",
      "2024-12-15 16:42:05.495397: Epoch time: 56.75 s\n",
      "EarlyStopping: 97 / 100\n",
      "2024-12-15 16:42:06.314111: \n",
      "2024-12-15 16:42:06.314111: Epoch 111\n",
      "2024-12-15 16:42:06.319456: Current learning rate: 0.009\n",
      "2024-12-15 16:43:03.040395: train_loss -0.4962\n",
      "2024-12-15 16:43:03.041396: val_loss -0.5472\n",
      "2024-12-15 16:43:03.048413: Pseudo dice [0.682, 0.7244]\n",
      "2024-12-15 16:43:03.053417: Epoch time: 56.73 s\n",
      "EarlyStopping: 98 / 100\n",
      "2024-12-15 16:43:03.750777: \n",
      "2024-12-15 16:43:03.751776: Epoch 112\n",
      "2024-12-15 16:43:03.757282: Current learning rate: 0.00899\n",
      "2024-12-15 16:44:00.655293: train_loss -0.5131\n",
      "2024-12-15 16:44:00.655293: val_loss -0.5176\n",
      "2024-12-15 16:44:00.662429: Pseudo dice [0.7051, 0.6944]\n",
      "2024-12-15 16:44:00.666931: Epoch time: 56.91 s\n",
      "EarlyStopping: 99 / 100\n",
      "2024-12-15 16:44:01.356131: \n",
      "2024-12-15 16:44:01.356652: Epoch 113\n",
      "2024-12-15 16:44:01.361874: Current learning rate: 0.00898\n",
      "2024-12-15 16:44:58.086589: train_loss -0.5088\n",
      "2024-12-15 16:44:58.087093: val_loss -0.4997\n",
      "2024-12-15 16:44:58.093606: Pseudo dice [0.7123, 0.5086]\n",
      "2024-12-15 16:44:58.098623: Epoch time: 56.73 s\n",
      "EarlyStopping: 100 / 100\n",
      "2024-12-15 16:44:58.782951: EarlyStopping: Stop training\n",
      "2024-12-15 16:44:59.158063: Training done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:1184: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename_or_checkpoint, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-15 16:44:59.516366: Using splits from existing split file: C:\\Users\\mrtwe\\TFM\\nnUNet-em\\nnUNet_preprocessed_data\\Dataset100_NewLesions\\splits_final.json\n",
      "2024-12-15 16:44:59.517754: The split file contains 5 splits.\n",
      "2024-12-15 16:44:59.525392: Desired fold for training: 3\n",
      "2024-12-15 16:44:59.531114: This split has 65 training and 16 validation cases.\n",
      "2024-12-15 16:44:59.537545: predicting FIS_007_01\n",
      "2024-12-15 16:44:59.543139: FIS_007_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:03.634127: predicting FIS_033_01\n",
      "2024-12-15 16:45:03.639113: FIS_033_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:06.743939: predicting FIS_067_01\n",
      "2024-12-15 16:45:06.748953: FIS_067_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:09.854770: predicting FIS_094_01\n",
      "2024-12-15 16:45:09.859789: FIS_094_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:12.996830: predicting FIS_102_01\n",
      "2024-12-15 16:45:13.001841: FIS_102_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:16.111539: predicting FIS_117_01\n",
      "2024-12-15 16:45:16.117043: FIS_117_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:19.229426: predicting REHEM_107_01\n",
      "2024-12-15 16:45:19.234426: REHEM_107_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:22.343835: predicting REHEM_13_01\n",
      "2024-12-15 16:45:22.348655: REHEM_13_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:25.454621: predicting REHEM_21_01\n",
      "2024-12-15 16:45:25.460637: REHEM_21_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:28.608119: predicting REHEM_55_01\n",
      "2024-12-15 16:45:28.612121: REHEM_55_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:31.728347: predicting REHEM_58_01\n",
      "2024-12-15 16:45:31.732345: REHEM_58_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:34.850960: predicting REHEM_60_01\n",
      "2024-12-15 16:45:34.854959: REHEM_60_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:37.972158: predicting REHEM_67_01\n",
      "2024-12-15 16:45:37.976160: REHEM_67_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:41.092020: predicting REHEM_82_01\n",
      "2024-12-15 16:45:41.097028: REHEM_82_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:44.209963: predicting REHEM_84_01\n",
      "2024-12-15 16:45:44.214467: REHEM_84_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:47.333978: predicting REHEM_86_01\n",
      "2024-12-15 16:45:47.338999: REHEM_86_01, shape torch.Size([2, 182, 218, 182]), rank 0\n",
      "2024-12-15 16:45:55.204088: Validation complete\n",
      "2024-12-15 16:45:55.204088: Mean Validation Dice:  0.5708894511804365\n"
     ]
    }
   ],
   "source": [
    "# NNUNetConfig().export_paths_to_env()\n",
    "\n",
    "run_training(\n",
    "        dataset_name_or_id=\"100\",\n",
    "        fold=\"3\",\n",
    "        device=device,\n",
    "        configuration=NNUNetConfig().CONFIGURATION,\n",
    "        trainer_class_name=\"nnUNetTrainerCustomOversamplingEarlyStopping\",\n",
    "        export_validation_probabilities=True,\n",
    "        continue_training=False,\n",
    "        val_with_best=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
